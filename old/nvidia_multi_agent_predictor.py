import os
import json
import re
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from newsapi import NewsApiClient
from playwright.sync_api import sync_playwright
from google import genai
from pydantic import BaseModel, Field

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Gemini API ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_JY")
if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY_JYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = genai.Client(api_key=GEMINI_API_KEY)

# NewsAPI í´ë¼ì´ì–¸íŠ¸
NEWS_API_KEY = 'dcc50abaec994513939365149361eee1'
news_api = NewsApiClient(api_key=NEWS_API_KEY)

# ì‹ ë¢° ì†ŒìŠ¤ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸
TRUSTED_SOURCES = {
    'reuters': 1.0,
    'bloomberg': 1.0,
    'wall street journal': 1.0,
    'financial times': 0.9,
    'associated press': 0.9,
    'cnbc': 0.8,
    'marketwatch': 0.8,
    'yahoo finance': 0.7,
    'investing.com': 0.6
}

# ì‹ ë¢°ë„ ì„ê³„ì¹˜
CONFIDENCE_THRESHOLD = 60


# ============================================================================
# Pydantic ëª¨ë¸ ì •ì˜ (êµ¬ì¡°í™”ëœ ì¶œë ¥ìš©)
# ============================================================================

class SearchKeywords(BaseModel):
    """í‚¤ì›Œë“œ ì—ì´ì „íŠ¸ ì¶œë ¥"""
    keywords: List[str] = Field(description="ê²€ìƒ‰ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (10ê°œ)")
    reasoning: str = Field(description="í‚¤ì›Œë“œ ì„ íƒ ì´ìœ ")


class NewsPack(BaseModel):
    """ë‰´ìŠ¤íŒ© êµ¬ì¡°"""
    pack_id: str = Field(description="ë‰´ìŠ¤íŒ© ID (ì˜ˆ: pack_001)")
    event_type: str = Field(description="ì´ë²¤íŠ¸ ìœ í˜•: earnings/policy/product/supply/partnership/general")
    summary: str = Field(description="í•µì‹¬ ë‚´ìš© ìš”ì•½ (3-5ë¬¸ì¥)")
    relevance_score: float = Field(description="NVIDIA ê´€ë ¨ì„± ì ìˆ˜ (0.0-1.0)")
    article_indices: List[int] = Field(description="í¬í•¨ëœ ê¸°ì‚¬ ì¸ë±ìŠ¤")


class NewsPacks(BaseModel):
    """ë³‘í•© ì—ì´ì „íŠ¸ ì¶œë ¥"""
    packs: List[NewsPack] = Field(description="ë‰´ìŠ¤íŒ© ë¦¬ìŠ¤íŠ¸ (5-10ê°œ)")


class Evidence(BaseModel):
    """ê·¼ê±° ì •ë³´"""
    event_type: str = Field(description="ì´ë²¤íŠ¸ ìœ í˜•")
    sentence: str = Field(description="ê·¼ê±° ë¬¸ì¥")


class EventScores(BaseModel):
    """ì´ë²¤íŠ¸ë³„ ì ìˆ˜ - Dict ëŒ€ì‹  ëª…ì‹œì  í•„ë“œ ì‚¬ìš©"""
    earnings: float = Field(default=0.0, description="ì‹¤ì  ê´€ë ¨ ì ìˆ˜ (-3 ~ +3)", ge=-3.0, le=3.0)
    policy: float = Field(default=0.0, description="ì •ì±…/ê·œì œ ì ìˆ˜ (-3 ~ +3)", ge=-3.0, le=3.0)
    product: float = Field(default=0.0, description="ì œí’ˆ ê´€ë ¨ ì ìˆ˜ (-3 ~ +3)", ge=-3.0, le=3.0)
    supply: float = Field(default=0.0, description="ê³µê¸‰ë§ ì ìˆ˜ (-3 ~ +3)", ge=-3.0, le=3.0)
    partnership: float = Field(default=0.0, description="íŒŒíŠ¸ë„ˆì‹­ ì ìˆ˜ (-3 ~ +3)", ge=-3.0, le=3.0)
    

class SentimentAnalysis(BaseModel):
    """ë¶„ì„ ì—ì´ì „íŠ¸ ì¶œë ¥"""
    overall_sentiment: float = Field(description="ì „ì²´ ê°ì„± ì ìˆ˜ (-3.0 ~ +3.0)", ge=-3.0, le=3.0)
    event_scores: EventScores = Field(description="ì´ë²¤íŠ¸ë³„ ì ìˆ˜")
    evidences: List[Evidence] = Field(description="ê·¼ê±° ë¦¬ìŠ¤íŠ¸ (ìµœì†Œ 3ê°œ)")
    optimal_timeframe: int = Field(description="ìµœì  ì˜ˆì¸¡ ê¸°ê°„ (1-14ì¼)", ge=1, le=14)
    direction: str = Field(description="ì˜ˆì¸¡ ë°©í–¥: Up/Down/Hold ì¤‘ í•˜ë‚˜")


class ValidationResult(BaseModel):
    """ê²€ì¦ ì—ì´ì „íŠ¸ ì¶œë ¥"""
    confidence: int = Field(description="ìµœì¢… ì‹ ë¢°ë„ (0-100)", ge=0, le=100)
    is_valid: bool = Field(description="ì„ê³„ì¹˜ í†µê³¼ ì—¬ë¶€")
    validation_notes: List[str] = Field(description="ê²€ì¦ ì‚¬í•­")
    contra_arguments: List[str] = Field(description="ë°˜ëŒ€ ê·¼ê±°")


# ============================================================================
# ì—ì´ì „íŠ¸ 1: í‚¤ì›Œë“œ ì—ì´ì „íŠ¸
# ============================================================================

class KeywordAgent:
    """ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„± ì—ì´ì „íŠ¸ - Gemini êµ¬ì¡°í™”ëœ ì¶œë ¥ ì‚¬ìš©"""
    
    def __init__(self, client: genai.Client):
        self.client = client
        self.model = "gemini-2.5-flash"
        
        # í´ë°± ê¸°ë³¸ í‚¤ì›Œë“œ
        self.default_keywords = [
            "NVIDIA earnings report",
            "NVDA stock forecast",
            "NVIDIA AI chip demand",
            "NVIDIA data center revenue",
            "NVIDIA China export ban",
            "Jensen Huang NVIDIA",
            "NVIDIA Blackwell GPU",
            "NVIDIA quarterly guidance",
            "NVIDIA partnership news",
            "NVIDIA supply chain"
        ]
    
    def generate_keywords(self) -> List[str]:
        """ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±"""
        print("\n" + "="*80)
        print("[ì—ì´ì „íŠ¸ 1] í‚¤ì›Œë“œ ìƒì„±")
        print("="*80)
        
        try:
            prompt = f"""ë‹¹ì‹ ì€ ê¸ˆìœµ ë‰´ìŠ¤ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. NVIDIA(NVDA) ì£¼ê°€ ì˜ˆì¸¡ì„ ìœ„í•œ ê²€ìƒ‰ í‚¤ì›Œë“œ 10ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.

í˜„ì¬ ë‚ ì§œ: {datetime.now().strftime("%Y-%m-%d")}

ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìƒì„±:
- ì œí’ˆ/ê¸°ìˆ  (2ê°œ): AI chip, GPU, Hopper, Blackwell
- ì •ì±…/ê·œì œ (2ê°œ): China, export control, regulation
- ì¬ë¬´ (2ê°œ): earnings, revenue, guidance
- íŒŒíŠ¸ë„ˆì‹­ (2ê°œ): partnership, deal, customer
- ê³µê¸‰ë§ (2ê°œ): TSMC, supply chain, manufacturing

ê° í‚¤ì›Œë“œëŠ” "NVIDIA" ë˜ëŠ” "NVDA"ë¥¼ í¬í•¨í•˜ê³  ì˜ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
ê²€ìƒ‰ì— íš¨ê³¼ì ì¸ êµ¬ì²´ì ì¸ êµ¬ë¬¸ì„ ì‚¬ìš©í•˜ì„¸ìš”."""

            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config={
                    'response_mime_type': 'application/json',
                    'response_schema': SearchKeywords,
                }
            )
            
            # êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹±
            result: SearchKeywords = response.parsed
            
            if result and result.keywords and len(result.keywords) >= 5:
                keywords = result.keywords[:10]  # ìµœëŒ€ 10ê°œ
                
                print(f"\nìƒì„±ëœ ê²€ìƒ‰ì–´ ({len(keywords)}ê°œ):")
                for i, kw in enumerate(keywords, 1):
                    print(f"  {i}. {kw}")
                print(f"\nìƒì„± ì´ìœ : {result.reasoning[:200]}...")
                
                return keywords
            else:
                raise Exception("í‚¤ì›Œë“œ ìˆ˜ ë¶€ì¡±")
            
        except Exception as e:
            print(f"\nâš ï¸ í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            print("ê¸°ë³¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
            for i, kw in enumerate(self.default_keywords, 1):
                print(f"  {i}. {kw}")
            
            return self.default_keywords


# ============================================================================
# ì—ì´ì „íŠ¸ 2: ë‰´ìŠ¤ ìˆ˜ì§‘ ì—ì´ì „íŠ¸
# ============================================================================

class CrawlerAgent:
    """ë‰´ìŠ¤ ìˆ˜ì§‘ ë° í¬ë¡¤ë§ ì—ì´ì „íŠ¸ - ë‹¤ì¤‘ ì†ŒìŠ¤, ì¤‘ë³µ ì œê±°, ì—”í‹°í‹° ë§í¬"""
    
    def __init__(self, news_api, genai_client: genai.Client):
        self.news_api = news_api
        self.client = genai_client
        self.model = "gemini-2.5-flash"
    
    def fetch_news(self, keywords: List[str], days_back: int = 30) -> List[Dict[str, Any]]:
        """NewsAPIë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        print("\n" + "="*80)
        print("[ì—ì´ì „íŠ¸ 2] ë‰´ìŠ¤ ìˆ˜ì§‘")
        print("="*80)
        
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days_back)
        
        all_articles = []
        seen_urls = set()
        
        for keyword in keywords:
            try:
                print(f"\nê²€ìƒ‰ ì¤‘: '{keyword}'")
                response = self.news_api.get_everything(
                    q=keyword,
                    from_param=start_date,
                    to=end_date,
                    language='en',
                    sort_by='relevancy',
                    page_size=15  # í‚¤ì›Œë“œë‹¹ 15ê°œ
                )
                
                for article in response.get('articles', []):
                    url = article.get('url')
                    title = article.get('title', '')
                    description = article.get('description', '')
                    
                    # ì¤‘ë³µ ì œê±°
                    if url and url not in seen_urls:
                        # NVIDIA ê´€ë ¨ì„± LLMìœ¼ë¡œ í™•ì¸
                        if self._is_nvidia_related(title, description):
                            seen_urls.add(url)
                            all_articles.append({
                                'title': title,
                                'description': description,
                                'url': url,
                                'publishedAt': article.get('publishedAt', ''),
                                'source': article.get('source', {}).get('name', ''),
                                'content': article.get('content', '')
                            })
                            print(f"  âœ“ {title[:60]}...")
                
            except Exception as e:
                print(f"  âœ— ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                continue
        
        # ë‚ ì§œìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
        all_articles.sort(key=lambda x: x['publishedAt'], reverse=True)
        
        print(f"\nì´ {len(all_articles)}ê°œì˜ NVIDIA ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        return all_articles
    
    def _is_nvidia_related(self, title: str, description: str) -> bool:
        """LLMì„ ì‚¬ìš©í•œ NVIDIA ê´€ë ¨ì„± í™•ì¸"""
        # ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ë°”ë¡œ ê±°ë¶€
        if not title and not description:
            return False
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì‚¬ì „ í•„í„° (API í˜¸ì¶œ ìµœì†Œí™”)
        text = f"{title} {description}".lower()
        if 'nvidia' in text or 'nvda' in text:
            return True
        
        # ì• ë§¤í•œ ê²½ìš°ë§Œ LLMì— ì§ˆì˜ (API í˜¸ì¶œ ì ˆì•½)
        try:
            prompt = f"""ë‹¤ìŒ ë‰´ìŠ¤ê°€ NVIDIA Corporation (NVDA) ì£¼ê°€ì™€ ê´€ë ¨ì´ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

ì œëª©: {title}
ì„¤ëª…: {description[:200]}

NVIDIA ê´€ë ¨ì´ë©´ "YES", ì•„ë‹ˆë©´ "NO"ë§Œ ë‹µí•˜ì„¸ìš”."""

            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt
            )
            
            answer = response.text.strip().upper()
            return 'YES' in answer
            
        except:
            # LLM ì‹¤íŒ¨ ì‹œ ë³´ìˆ˜ì ìœ¼ë¡œ í¬í•¨
            return True
    
    def crawl_articles(self, articles: List[Dict[str, Any]], max_crawl: int = 20) -> List[Dict[str, Any]]:
        """Playwrightë¡œ ê¸°ì‚¬ ë³¸ë¬¸ í¬ë¡¤ë§"""
        print("\nê¸°ì‚¬ ë³¸ë¬¸ í¬ë¡¤ë§ ì¤‘...")
        
        crawled = []
        for idx, article in enumerate(articles[:max_crawl]):
            print(f"  [{idx+1}/{min(max_crawl, len(articles))}] {article['title'][:50]}...")
            
            content = self._crawl_single_article(article['url'])
            crawled.append({
                **article,
                'full_content': content if content else article.get('description', '')
            })
        
        print(f"âœ“ {len(crawled)}ê°œ ê¸°ì‚¬ í¬ë¡¤ë§ ì™„ë£Œ")
        return crawled
    
    def _crawl_single_article(self, url: str) -> Optional[str]:
        """ë‹¨ì¼ ê¸°ì‚¬ í¬ë¡¤ë§"""
        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                page = browser.new_page()
                page.goto(url, timeout=10000)
                page.wait_for_timeout(1500)
                
                # ë³¸ë¬¸ ì¶”ì¶œ
                content = ""
                selectors = ['article', '[role="article"]', '.article-content', 'main', 'body']
                
                for selector in selectors:
                    try:
                        element = page.query_selector(selector)
                        if element:
                            content = element.inner_text()
                            if len(content) > 200:  # ì¶©ë¶„í•œ ë‚´ìš©ì´ ìˆìœ¼ë©´
                                break
                    except:
                        continue
                
                browser.close()
                return content[:3000]  # í† í° ì œí•œ
                
        except Exception as e:
            return None


# ============================================================================
# ì—ì´ì „íŠ¸ 3: ë³‘í•©Â·ì •ì œ ì—ì´ì „íŠ¸
# ============================================================================

class MergeAgent:
    """ë‰´ìŠ¤ ë³‘í•© ë° ì •ì œ ì—ì´ì „íŠ¸ - Gemini êµ¬ì¡°í™”ëœ ì¶œë ¥ ì‚¬ìš©"""
    
    def __init__(self, client: genai.Client):
        self.client = client
        self.model = "gemini-2.0-flash-exp"
    
    def merge_and_refine(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ë‰´ìŠ¤ë¥¼ ë‰´ìŠ¤íŒ©ìœ¼ë¡œ ë³‘í•©Â·ì •ì œ"""
        print("\n" + "="*80)
        print("[ì—ì´ì „íŠ¸ 3] ë‰´ìŠ¤ ë³‘í•© ë° ì •ì œ")
        print("="*80)
        
        if not articles:
            return []
        
        # ê¸°ì‚¬ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ë§Œ ì„ íƒ
        articles = articles[:20]
        
        # ê¸°ì‚¬ ëª©ë¡ í…ìŠ¤íŠ¸ ìƒì„±
        news_list = ""
        for idx, article in enumerate(articles):
            news_list += f"[{idx}] {article['title']}\n"
            news_list += f"ì¶œì²˜: {article['source']} | {article['publishedAt'][:10]}\n"
            content = article.get('full_content', article.get('description', ''))[:300]
            news_list += f"{content}...\n\n"
        
        try:
            prompt = f"""NVIDIA ê´€ë ¨ ë‰´ìŠ¤ë“¤ì„ ë¶„ì„í•˜ê³  ì´ë²¤íŠ¸ë³„ë¡œ ê·¸ë£¹í™”í•˜ì„¸ìš”.

ë‰´ìŠ¤ ëª©ë¡:
{news_list[:10000]}

ì„ë¬´:
1. ì¤‘ë³µ/ì¬íƒ• ê¸°ì‚¬ë¥¼ ê°™ì€ ì´ë²¤íŠ¸ë¡œ ë¬¶ê¸°
2. ì´ë²¤íŠ¸ ìœ í˜•ë³„ ë¶„ë¥˜
3. ê° ë‰´ìŠ¤íŒ©ë§ˆë‹¤ í•µì‹¬ ë‚´ìš© 3-5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½
4. NVIDIA ê´€ë ¨ì„± ì ìˆ˜ (0.0~1.0) ë¶€ì—¬

ì´ë²¤íŠ¸ ìœ í˜•:
- earnings: ì‹¤ì , ë§¤ì¶œ, EPS
- policy: ê·œì œ, ì •ì±…, ìˆ˜ì¶œí†µì œ
- product: ì‹ ì œí’ˆ, GPU, ì¹©
- supply: ê³µê¸‰ë§, ì œì¡°
- partnership: íŒŒíŠ¸ë„ˆì‹­, í˜‘ì—…
- general: ê¸°íƒ€

5~8ê°œì˜ ë‰´ìŠ¤íŒ©ì„ ìƒì„±í•˜ì„¸ìš”."""

            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config={
                    'response_mime_type': 'application/json',
                    'response_schema': NewsPacks,
                }
            )
            
            # êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹±
            result: NewsPacks = response.parsed
            
            if result and result.packs:
                news_packs = [pack.model_dump() for pack in result.packs]
                
                print(f"\nâœ“ {len(news_packs)}ê°œì˜ ë‰´ìŠ¤íŒ© ìƒì„±:")
                for pack in news_packs:
                    print(f"  - {pack['event_type'].upper()}: {pack['summary'][:60]}... "
                          f"(ê´€ë ¨ì„±: {pack['relevance_score']:.2f})")
                return news_packs
            else:
                raise Exception("ë‰´ìŠ¤íŒ© ìƒì„± ì‹¤íŒ¨")
            
        except Exception as e:
            print(f"âš ï¸ ë³‘í•© ì‹¤íŒ¨: {e}")
            print("ê° ê¸°ì‚¬ë¥¼ ê°œë³„ ë‰´ìŠ¤íŒ©ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            
            # í´ë°±: ê° ê¸°ì‚¬ë¥¼ ê°œë³„ ë‰´ìŠ¤íŒ©ìœ¼ë¡œ
            fallback_packs = []
            for idx, article in enumerate(articles[:10]):
                fallback_packs.append({
                    'pack_id': f'pack_{idx:03d}',
                    'event_type': 'general',
                    'summary': article['title'] + ". " + article.get('description', '')[:200],
                    'relevance_score': 0.7,
                    'article_indices': [idx]
                })
            
            return fallback_packs


# ============================================================================
# ì—ì´ì „íŠ¸ 4: ë¶„ì„ ì—ì´ì „íŠ¸
# ============================================================================

class AnalysisAgent:
    """ê°ì„± ë° ì´ë²¤íŠ¸ ë¶„ì„ ì—ì´ì „íŠ¸ - Gemini êµ¬ì¡°í™”ëœ ì¶œë ¥ ì‚¬ìš©"""
    
    def __init__(self, client: genai.Client):
        self.client = client
        self.model = "gemini-2.0-flash-exp"
        
        # ì´ë²¤íŠ¸ë³„ ê°€ì¤‘ì¹˜ ë° ì˜ˆì¸¡ ê¸°ê°„
        self.event_settings = {
            'earnings': {'weight': 3.0, 'days': (3, 7)},
            'guidance': {'weight': 2.5, 'days': (5, 10)},
            'policy': {'weight': 2.0, 'days': (7, 14)},
            'product': {'weight': 1.5, 'days': (5, 10)},
            'supply': {'weight': 1.0, 'days': (7, 14)},
            'partnership': {'weight': 1.2, 'days': (3, 7)},
            'general': {'weight': 0.5, 'days': (5, 10)}
        }
    
    def analyze(self, news_packs: List[Dict[str, Any]], articles: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ê°ì„± ë¶„ì„ ë° ì´ë²¤íŠ¸ ì¶”ì¶œ"""
        print("\n" + "="*80)
        print("[ì—ì´ì „íŠ¸ 4] ê°ì„± ë° ì´ë²¤íŠ¸ ë¶„ì„")
        print("="*80)
        
        # ë‰´ìŠ¤íŒ© ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = ""
        for pack in news_packs[:10]:
            context += f"\n[{pack['event_type'].upper()}] ê´€ë ¨ì„±: {pack.get('relevance_score', 0.5):.2f}\n"
            context += f"{pack['summary'][:400]}\n"
            context += "-" * 60 + "\n"
        
        try:
            prompt = f"""ë‹¹ì‹ ì€ NVIDIA ì£¼ê°€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ê³  ì£¼ê°€ ì˜ˆì¸¡ì„ ì œê³µí•˜ì„¸ìš”.

í˜„ì¬ ë‚ ì§œ: {datetime.now().strftime("%Y-%m-%d")}

ë¶„ì„ ëŒ€ìƒ ë‰´ìŠ¤:
{context[:8000]}

ë‹¤ìŒì„ ë¶„ì„í•˜ì„¸ìš”:

1. overall_sentiment: ì „ì²´ ê°ì„± ì ìˆ˜ (-3.0 ~ +3.0 ì‚¬ì´ì˜ ì‹¤ìˆ˜)
   - ì‹¤ì  í˜¸ì¡°, ì‹ ì œí’ˆ ì„±ê³µ = ê¸ì • (+2 ~ +3)
   - ì‹¤ì  ë¯¸ë‹¬, ê·œì œ ê°•í™” = ë¶€ì • (-2 ~ -3)
   - ì¤‘ë¦½ = 0

2. event_scores: ê° ì´ë²¤íŠ¸ë³„ ì ìˆ˜ë¥¼ ê°œë³„ í•„ë“œë¡œ
   - earnings: ì‹¤ì  ê´€ë ¨ ì ìˆ˜ (-3.0 ~ +3.0)
   - policy: ì •ì±…/ê·œì œ ì ìˆ˜ (-3.0 ~ +3.0)
   - product: ì œí’ˆ ê´€ë ¨ ì ìˆ˜ (-3.0 ~ +3.0)
   - supply: ê³µê¸‰ë§ ì ìˆ˜ (-3.0 ~ +3.0)
   - partnership: íŒŒíŠ¸ë„ˆì‹­ ì ìˆ˜ (-3.0 ~ +3.0)

3. evidences: ê·¼ê±° ë¦¬ìŠ¤íŠ¸ (ìµœì†Œ 3ê°œ)
   - ê° ê·¼ê±°ëŠ” event_typeê³¼ sentence í¬í•¨
   - event_type: earnings/policy/product/supply/partnership/general

4. optimal_timeframe: ì˜ˆì¸¡ ê¸°ê°„ (1~14 ì‚¬ì´ì˜ ì •ìˆ˜)
   - earnings: 3-7ì¼
   - policy: 7-14ì¼
   - ê¸°íƒ€: 5-10ì¼

5. direction: "Up", "Down", "Hold" ì¤‘ í•˜ë‚˜ (ì •í™•íˆ ì´ ë¬¸ìì—´)

ì£¼ì˜: ëª¨ë“  í•„ë“œë¥¼ ë°˜ë“œì‹œ ì±„ì›Œì•¼ í•©ë‹ˆë‹¤. ê´€ë ¨ ì—†ëŠ” ì´ë²¤íŠ¸ëŠ” 0.0ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”."""

            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config={
                    'response_mime_type': 'application/json',
                    'response_schema': SentimentAnalysis,
                }
            )
            
            # êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹±
            result: SentimentAnalysis = response.parsed
            
            if result:
                # event_scoresë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                event_scores_dict = result.event_scores.model_dump()
                
                result_dict = {
                    'overall_sentiment': result.overall_sentiment,
                    'event_scores': event_scores_dict,
                    'evidences': [e.model_dump() for e in result.evidences],
                    'optimal_timeframe': result.optimal_timeframe,
                    'direction': result.direction
                }
                
                print(f"\nâœ“ ë¶„ì„ ì„±ê³µ")
                print(f"ì „ì²´ ê°ì„±: {result.overall_sentiment:+.1f}")
                print(f"ì´ë²¤íŠ¸ë³„ ì ìˆ˜:")
                for event, score in event_scores_dict.items():
                    if score != 0:
                        print(f"  - {event}: {score:+.1f}")
                print(f"ìµœì  ì˜ˆì¸¡ ê¸°ê°„: {result.optimal_timeframe}ì¼")
                print(f"ì˜ˆì¸¡ ë°©í–¥: {result.direction}")
                
                return result_dict
            else:
                raise Exception("response.parsedê°€ None")
            
        except Exception as e:
            print(f"âš ï¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            print(f"ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            import traceback
            print(f"ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")
            print("ê¸°ë³¸ ë¶„ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
            # í´ë°±: ë‹¨ìˆœ ì¶”ì •
            sentiment = self._simple_sentiment(news_packs)
            
            return {
                'overall_sentiment': sentiment,
                'event_scores': {'general': sentiment},
                'evidences': [{'event_type': 'general', 'sentence': 'ìë™ ë¶„ì„ ì‹¤íŒ¨, ë‹¨ìˆœ ì¶”ì •'}],
                'optimal_timeframe': 7,
                'direction': 'Up' if sentiment > 0 else ('Down' if sentiment < 0 else 'Hold')
            }
    
    def _simple_sentiment(self, news_packs: List[Dict[str, Any]]) -> float:
        """ê°„ë‹¨í•œ ê°ì„± ì¶”ì • (í´ë°±ìš©)"""
        if not news_packs:
            return 0.0
        
        avg_relevance = sum(pack.get('relevance_score', 0.5) for pack in news_packs) / len(news_packs)
        return (avg_relevance - 0.5) * 2  # -1 ~ 1 ë²”ìœ„


# ============================================================================
# ì—ì´ì „íŠ¸ 5: ê²€ì¦ ì—ì´ì „íŠ¸
# ============================================================================

class ValidationAgent:
    """ê²€ì¦ ì—ì´ì „íŠ¸ - ì‚¬ì‹¤ ê²€ì¦, ì¼ê´€ì„± ì²´í¬, Devil's Advocate"""
    
    def __init__(self, client: genai.Client):
        self.client = client
        self.model = "gemini-2.0-flash-exp"
    
    def validate(self, 
                 analysis: Dict[str, Any],
                 news_packs: List[Dict[str, Any]],
                 articles: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ê²€ì¦ ë° ì‹ ë¢°ë„ ê³„ì‚°"""
        print("\n" + "="*80)
        print("[ì—ì´ì „íŠ¸ 5] ê²°ê³¼ ê²€ì¦")
        print("="*80)
        
        # 1. ì¶œì²˜ ì‹ ë¢°ë„ ê³„ì‚°
        source_score = self._calculate_source_quality(articles)
        
        # 2. ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°
        consistency_score = self._calculate_consistency(news_packs)
        
        # 3. ìµœì‹ ì„± ì ìˆ˜
        recency_score = self._calculate_recency(articles)
        
        # 4. Devil's Advocate - ë°˜ëŒ€ ê·¼ê±° ì°¾ê¸°
        contra_args = self._find_counter_arguments(analysis, news_packs)
        
        # 5. ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
        confidence = int(
            source_score * 40 +
            consistency_score * 30 +
            recency_score * 20 +
            min(abs(analysis.get('overall_sentiment', 0)) * 3.33, 10)  # ê°ì„± ê°•ë„ 10%
        )
        
        is_valid = confidence >= CONFIDENCE_THRESHOLD
        
        print(f"\nì‹ ë¢°ë„ ë¶„ì„:")
        print(f"  - ì¶œì²˜ í’ˆì§ˆ: {source_score:.1%} (ê°€ì¤‘ì¹˜ 40%)")
        print(f"  - ì¼ê´€ì„±: {consistency_score:.1%} (ê°€ì¤‘ì¹˜ 30%)")
        print(f"  - ìµœì‹ ì„±: {recency_score:.1%} (ê°€ì¤‘ì¹˜ 20%)")
        print(f"  - ê°ì„± ê°•ë„: {abs(analysis.get('overall_sentiment', 0)):.1f}")
        print(f"\nìµœì¢… ì‹ ë¢°ë„: {confidence}%")
        print(f"ì„ê³„ì¹˜ í†µê³¼: {'âœ“ YES' if is_valid else 'âœ— NO (ì˜ˆì¸¡ ë³´ë¥˜)'}")
        
        if contra_args:
            print(f"\në°˜ëŒ€ ê·¼ê±°:")
            for arg in contra_args:
                print(f"  âš ï¸  {arg}")
        
        validation_notes = [
            f"ì¶œì²˜ ì‹ ë¢°ë„: {source_score:.0%}",
            f"ì¼ê´€ì„± ì ìˆ˜: {consistency_score:.0%}",
            f"ìµœì‹ ì„±: {recency_score:.0%}"
        ]
        
        return {
            'confidence': confidence,
            'is_valid': is_valid,
            'validation_notes': validation_notes,
            'contra_arguments': contra_args
        }
    
    def _calculate_source_quality(self, articles: List[Dict[str, Any]]) -> float:
        """ì¶œì²˜ ì‹ ë¢°ë„ ì ìˆ˜"""
        if not articles:
            return 0.0
        
        scores = []
        for article in articles:
            source = article.get('source', '').lower()
            score = 0.5  # ê¸°ë³¸ê°’
            for trusted, weight in TRUSTED_SOURCES.items():
                if trusted in source:
                    score = weight
                    break
            scores.append(score)
        
        return sum(scores) / len(scores)
    
    def _calculate_consistency(self, news_packs: List[Dict[str, Any]]) -> float:
        """ì¼ê´€ì„± ì ìˆ˜ - ì—¬ëŸ¬ ë‰´ìŠ¤íŒ©ì´ ê°™ì€ ë°©í–¥ì„ ê°€ë¦¬í‚¤ëŠ”ì§€"""
        if len(news_packs) < 2:
            return 0.6  # ë‰´ìŠ¤ ì ìœ¼ë©´ ì¤‘ê°„ ì ìˆ˜
        
        # ì´ë²¤íŠ¸ íƒ€ì… ë‹¤ì–‘ì„± (ì¢‹ìŒ)
        event_types = set(pack.get('event_type', '') for pack in news_packs)
        diversity = len(event_types) / len(news_packs)
        
        # ê´€ë ¨ì„± ì ìˆ˜ í‰ê· 
        relevance = sum(pack.get('relevance_score', 0) for pack in news_packs) / len(news_packs)
        
        return (diversity * 0.3 + relevance * 0.7)
    
    def _calculate_recency(self, articles: List[Dict[str, Any]]) -> float:
        """ìµœì‹ ì„± ì ìˆ˜"""
        if not articles:
            return 0.0
        
        now = datetime.now()
        recent_count = 0
        
        for article in articles:
            pub_date = article.get('publishedAt', '')
            try:
                pub_dt = datetime.fromisoformat(pub_date.replace('Z', '+00:00'))
                days_ago = (now - pub_dt).days
                if days_ago <= 7:  # 1ì£¼ì¼ ì´ë‚´
                    recent_count += 1
            except:
                continue
        
        return recent_count / len(articles)
    
    def _find_counter_arguments(self, analysis: Dict[str, Any], news_packs: List[Dict[str, Any]]) -> List[str]:
        """Devil's Advocate - ë°˜ëŒ€ ê·¼ê±° ì°¾ê¸°"""
        
        summary = "\n".join(pack.get('summary', '')[:200] for pack in news_packs[:3])
        
        prompt = f"""ë‹¹ì‹ ì€ ë¹„íŒì  ì‹¬ì‚¬ê´€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ì— ëŒ€í•œ ë°˜ëŒ€ ê·¼ê±°ë¥¼ ì°¾ìœ¼ì„¸ìš”.

**ë¶„ì„ ê²°ê³¼**:
- ì˜ˆì¸¡ ë°©í–¥: {analysis.get('direction', 'Unknown')}
- ê°ì„± ì ìˆ˜: {analysis.get('overall_sentiment', 0)}

**ë‰´ìŠ¤ ìš”ì•½**:
{summary}

**ì§ˆë¬¸**:
1. ê°„ê³¼ëœ ë¶€ì •ì  ìš”ì¸ì´ ìˆëŠ”ê°€?
2. ê³¼ëŒ€í‰ê°€ëœ ê¸ì •ì  ìš”ì¸ì´ ìˆëŠ”ê°€?
3. ì‹œì¥ ë§¥ë½ì—ì„œ ë†“ì¹œ ë¦¬ìŠ¤í¬ëŠ”?

ê°„ë‹¨íˆ 3ê°œ ì´í•˜ë¡œ ë°˜ëŒ€ ê·¼ê±°ë¥¼ ë‚˜ì—´í•˜ì„¸ìš”. ì—†ìœ¼ë©´ "ì—†ìŒ"ì´ë¼ê³ ë§Œ í•˜ì„¸ìš”.
"""
        
        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt
            )
            text = response.text
            
            if "ì—†ìŒ" in text or "None" in text:
                return []
            
            # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬
            args = [line.strip('- ').strip() for line in text.split('\n') if line.strip() and len(line.strip()) > 10]
            return args[:3]
            
        except:
            return []


# ============================================================================
# ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
# ============================================================================

class Orchestrator:
    """ë©€í‹°-ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° - ì „ì²´ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬"""
    
    def __init__(self):
        self.keyword_agent = KeywordAgent(client)
        self.crawler_agent = CrawlerAgent(news_api, client)  # client ì „ë‹¬
        self.merge_agent = MergeAgent(client)
        self.analysis_agent = AnalysisAgent(client)
        self.validation_agent = ValidationAgent(client)
    
    def run(self, user_query: str = "ì—”ë¹„ë””ì•„ ì£¼ê°€ê°€ ì˜¤ë¥¼ê¹Œ ë‚´ë¦´ê¹Œ?") -> Dict[str, Any]:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        print("\n" + "="*80)
        print("ğŸ¤– NVIDIA ì£¼ê°€ ì˜ˆì¸¡ ë©€í‹°-ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ")
        print("="*80)
        print(f"\nì‚¬ìš©ì ì§ˆì˜: \"{user_query}\"")
        print(f"ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # 1ë‹¨ê³„: í‚¤ì›Œë“œ ìƒì„±
            keywords = self.keyword_agent.generate_keywords()
            
            # 2ë‹¨ê³„: ë‰´ìŠ¤ ìˆ˜ì§‘
            articles = self.crawler_agent.fetch_news(keywords, days_back=30)
            
            if not articles:
                return self._create_failure_result("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ë³¸ë¬¸ í¬ë¡¤ë§
            crawled_articles = self.crawler_agent.crawl_articles(articles, max_crawl=20)
            
            # 3ë‹¨ê³„: ë‰´ìŠ¤ ë³‘í•© ë° ì •ì œ
            news_packs = self.merge_agent.merge_and_refine(crawled_articles)
            
            # 4ë‹¨ê³„: ê°ì„± ë° ì´ë²¤íŠ¸ ë¶„ì„
            analysis = self.analysis_agent.analyze(news_packs, crawled_articles)
            
            # 5ë‹¨ê³„: ê²€ì¦
            validation = self.validation_agent.validate(analysis, news_packs, crawled_articles)
            
            # ìµœì¢… ê²°ê³¼ ìƒì„±
            final_result = self._create_final_result(
                analysis, validation, news_packs, crawled_articles, keywords
            )
            
            return final_result
            
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return self._create_failure_result(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}")
    
    def _create_final_result(self, analysis, validation, news_packs, articles, keywords) -> Dict[str, Any]:
        """ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±"""
        
        # ê¸ì •/ë¶€ì • ìš”ì¸ ì¶”ì¶œ
        positive_factors = []
        negative_factors = []
        
        for evidence in analysis.get('evidences', []):
            event = evidence.get('event_type', evidence.get('event', ''))  # ë‘ í˜•ì‹ ëª¨ë‘ ì§€ì›
            sentence = evidence.get('sentence', '')
            score = analysis.get('event_scores', {}).get(event, 0)
            
            if score > 0:
                positive_factors.append(f"[{event}] {sentence}")
            elif score < 0:
                negative_factors.append(f"[{event}] {sentence}")
        
        # ìš”ì•½ ìƒì„±
        summary_parts = []
        for pack in news_packs[:3]:
            summary_parts.append(f"- {pack['event_type'].upper()}: {pack['summary'][:100]}...")
        
        summary = "\n".join(summary_parts)
        
        is_valid = validation['is_valid']
        reason_if_invalid = "" if is_valid else f"ì‹ ë¢°ë„ {validation['confidence']}%ë¡œ ì„ê³„ì¹˜ {CONFIDENCE_THRESHOLD}% ë¯¸ë‹¬"
        
        return {
            'timestamp': datetime.now().isoformat(),
            'user_query': "ì—”ë¹„ë””ì•„ ì£¼ê°€ ì˜ˆì¸¡",
            'keywords_used': keywords,
            'total_articles': len(articles),
            'news_packs': len(news_packs),
            'prediction': {
                'direction': analysis.get('direction', 'Hold'),
                'confidence': validation['confidence'],
                'timeframe': analysis.get('optimal_timeframe', 7),
                'positive_factors': positive_factors[:5],
                'negative_factors': negative_factors[:5],
                'summary': summary,
                'is_valid': is_valid,
                'reason_if_invalid': reason_if_invalid
            },
            'analysis_details': {
                'overall_sentiment': analysis.get('overall_sentiment', 0),
                'event_scores': analysis.get('event_scores', {}),
                'validation_notes': validation.get('validation_notes', []),
                'contra_arguments': validation.get('contra_arguments', [])
            },
            'news_packs': news_packs,
            'raw_articles': articles[:10]  # ìƒìœ„ 10ê°œë§Œ ì €ì¥
        }
    
    def _create_failure_result(self, reason: str) -> Dict[str, Any]:
        """ì‹¤íŒ¨ ê²°ê³¼ ìƒì„±"""
        return {
            'timestamp': datetime.now().isoformat(),
            'prediction': {
                'direction': 'Hold',
                'confidence': 0,
                'timeframe': 0,
                'positive_factors': [],
                'negative_factors': [],
                'summary': reason,
                'is_valid': False,
                'reason_if_invalid': reason
            }
        }


# ============================================================================
# ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜
# ============================================================================

def print_final_result(result: Dict[str, Any]):
    """ìµœì¢… ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
    
    print("\n\n")
    print("="*80)
    print("ğŸ“Š ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼")
    print("="*80)
    
    pred = result['prediction']
    
    if not pred['is_valid']:
        print("\nâš ï¸  ì˜ˆì¸¡ ë³´ë¥˜")
        print(f"ì‚¬ìœ : {pred['reason_if_invalid']}")
        print("\në” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•˜ê±°ë‚˜ ì‹œì¥ ë¶ˆí™•ì‹¤ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
        return
    
    # ë°©í–¥ ì´ëª¨ì§€
    direction_emoji = {
        'Up': 'ğŸ“ˆ ìƒìŠ¹',
        'Down': 'ğŸ“‰ í•˜ë½',
        'Hold': 'â¡ï¸  ë³´í•©'
    }
    
    print(f"\në°©í–¥: {direction_emoji.get(pred['direction'], pred['direction'])}")
    print(f"ì‹ ë¢°ë„: {pred['confidence']}%")
    print(f"ê¶Œì¥ ì˜ˆì¸¡ ê¸°ê°„: {pred['timeframe']}ì¼")
    
    if pred['positive_factors']:
        print(f"\nâœ… ê¸ì •ì  ìš”ì¸ ({len(pred['positive_factors'])}ê°œ):")
        for factor in pred['positive_factors']:
            print(f"   {factor}")
    
    if pred['negative_factors']:
        print(f"\nâŒ ë¶€ì •ì  ìš”ì¸ ({len(pred['negative_factors'])}ê°œ):")
        for factor in pred['negative_factors']:
            print(f"   {factor}")
    
    print(f"\nğŸ“ ë¶„ì„ ìš”ì•½:")
    print(pred['summary'])
    
    # ê²€ì¦ ì •ë³´
    details = result.get('analysis_details', {})
    if details.get('validation_notes'):
        print(f"\nğŸ” ê²€ì¦ ì •ë³´:")
        for note in details['validation_notes']:
            print(f"   â€¢ {note}")
    
    if details.get('contra_arguments'):
        print(f"\nâš ï¸  ë°˜ëŒ€ ì˜ê²¬ (Devil's Advocate):")
        for arg in details['contra_arguments']:
            print(f"   â€¢ {arg}")
    
    print("\n" + "="*80)


# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ë° ì‹¤í–‰
    orchestrator = Orchestrator()
    result = orchestrator.run()
    
    # ê²°ê³¼ ì¶œë ¥
    print_final_result(result)
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    output_file = f"nvidia_multi_agent_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ì „ì²´ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()

